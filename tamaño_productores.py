# -*- coding: utf-8 -*-
"""Tamaño productores.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1N8dwzdjRXxU3-gJyrLjPvo9Bs-4a_QhG

https://towardsdatascience.com/creating-an-interactive-dashboard-from-jupyter-notebook-with-voila-b64918b4d15a
https://pbpython.com/interactive-dashboards.html
https://voila.readthedocs.io/en/stable/deploy.html

- ipywidgets para hacerlo interactivo
- voila para hacerlo dashboard
- Heroku (link 1) o binder (link 2) para deploying y shearing (mas sobre deploying en link 3)

# Librerías y lectura de archivo
"""

#Motores de conexión
from sqlalchemy.engine import create_engine 
import mysql.connector

#import MySQLdb as sql_db

#Generales
import sys
import openpyxl


# Tratamiento de datos
# ==============================================================================
import pandas as pd
#import pandas_profiling
#from pandas_profiling import ProfileReport
import numpy as np
from numpy import mean
from numpy import std
import datetime
import math


# Gráficos
# ==============================================================================
import matplotlib.pyplot as plt
from matplotlib import style
import seaborn as sbn
import plotly.express as px
import plotly.graph_objects as gp


# Preprocesado y modelado
# ==============================================================================
from scipy.stats import pearsonr
from scipy.stats import kurtosis, skew
from scipy.stats import shapiro
from scipy.stats import normaltest
from scipy.stats import itemfreq

from sklearn.linear_model import LinearRegression
from sklearn.metrics import silhouette_score
from sklearn.model_selection import train_test_split
from sklearn.metrics import r2_score
from sklearn.metrics import mean_squared_error
from sklearn.cluster import KMeans
from sklearn.preprocessing import normalize
from sklearn.preprocessing import StandardScaler
from sklearn.decomposition import PCA
from sklearn.datasets import make_classification
from sklearn.model_selection import cross_val_score
from sklearn.model_selection import RepeatedStratifiedKFold
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import fbeta_score, accuracy_score, f1_score, precision_score, recall_score  # métricas para evaluar
from sklearn.metrics import make_scorer
from sklearn.dummy import DummyClassifier   
from sklearn.model_selection import GridSearchCV
from sklearn.metrics import plot_confusion_matrix  
from sklearn.metrics import confusion_matrix
from sklearn.metrics import classification_report

import statsmodels.api as sm                # modelos estadísticos
import statsmodels.stats.api as sms         # módulo stats de statsmodels
from statsmodels.stats.outliers_influence import reset_ramsey 
from statsmodels.stats.outliers_influence import variance_inflation_factor
import statsmodels.api as sm
import statsmodels.formula.api as smf
from statsmodels.stats.anova import anova_lm
from statsmodels.stats.outliers_influence import reset_ramsey 
import scipy
from collections import Counter


# Configuración matplotlib
# ==============================================================================
plt.rcParams['image.cmap'] = "bwr"
#plt.rcParams['figure.dpi'] = "100"
plt.rcParams['savefig.bbox'] = "tight"
style.use('ggplot') or plt.style.use('ggplot')

# Configuración
# ==============================================================================
import warnings
warnings.filterwarnings('ignore')
## Barras de progreso en los iteradores

df = pd.read_excel('tamaño.xlsx', sheet_name='Hoja4')

print('Procesado')

"""***
# Tabla de Productores

***Tabla de muestra:***
"""

productor = df.iloc[9:, 1:8]
new_header = productor.iloc[0] #grab the first row for the header
productor = productor[1:] #take the data less the header row
productor.columns = new_header #set the header row as the df header
productor.reset_index(drop=True, inplace=True)
productor.dropna(axis=0, how='all', inplace=True)

productor.sample(5)

"""***Cantidad de cuentas:***"""

duplicados = pd.DataFrame(productor['Cuenta'].value_counts())
print(duplicados['Cuenta'].value_counts())

"""***
## Datos de campañas

***Tabla de muestra:***

"""

df_h = df.iloc[9:, 8:23]
new_header = df_h.iloc[0] #grab the first row for the header
df_h = df_h[1:] #take the data less the header row
df_h.columns = new_header #set the header row as the df header
df_h.reset_index(drop=True, inplace=True)
df_h.dropna(axis=0, how='all', inplace=True)

columnas = df_h.columns
df_h['Cuenta'] = productor['Cuenta']
df_hm = pd.melt(df_h, id_vars=['Cuenta'], value_vars=columnas)


columnas = df_hm.columns

df_hm.rename(columns = {columnas[1]:'Cereal',columnas[2]:'Hectareas'}, inplace = True)
df_hm['Campaña'] = df_hm['Cereal'].str[-6:]
df_hm['Cereal'] = df_hm['Cereal'].str[:-6]
df_hm['Cereal'].value_counts()

df_hm[df_hm['Hectareas']>0].sample(10)

"""***Estructura de datos:***"""

df_hm.info()

"""### Depuración de productores inactivos (Has. totales = 0)

***Numero de inactivos:***
"""

#Conteo inactivos

inactivos = df_hm.groupby(['Cuenta']).sum()
inactivos.reset_index(drop=False,inplace=True)
inactivos = inactivos[inactivos['Hectareas']==0]
inactivos['Inactivo']='Si'
inactivos = inactivos[['Cuenta','Inactivo']]
inactivos['Inactivo'].value_counts()

#Dropeo de inactivos en las últimas 3 campañas

df_hma = pd.merge(df_hm, inactivos, how="left", on='Cuenta')#, left_index=True, right_index=True)
df_hma = df_hma[df_hma['Inactivo']!='Si']

"""## Análisis general

***Definición importante:***

Hectáreas sembradas = Trigo + Maíz 1° + Soja 1°

Hectáreas totales trabajadas = Hectáreas sembradas + Maíz 2° + Soja 2°

"""

#Segmentación de tipo

df_hma.loc[df_hma['Cereal'] == 'Trigo', 'Segmento'] = 'Sembradas'
df_hma.loc[df_hma['Cereal'] == 'Maíz 1º', 'Segmento'] = 'Sembradas'
df_hma.loc[df_hma['Cereal'] == 'Soja 1º', 'Segmento'] = 'Sembradas'

df_hma.loc[df_hma['Cereal'] == 'Soja 2º', 'Segmento'] = 'Total'
df_hma.loc[df_hma['Cereal'] == 'Maíz 2º', 'Segmento'] = 'Total'

"""### Análisis descriptivo de variable "Hectárea"

##### Hectáreas sembradas:
"""

#Valores de la variable > 0 
df_hma['Hectareas'] = df_hma['Hectareas'].astype('float')
df_hma[(df_hma['Hectareas']>0) & (df_hma['Segmento']=='Sembradas')]['Hectareas'].describe().round(2)

fig = px.box(df_hma[(df_hma['Hectareas']>0) & (df_hma['Segmento']=='Sembradas')], y="Hectareas", points="all")
#fig.update_traces(quartilemethod="exclusive")
fig.update_layout(title = "Boxplot de observaciones de hectáreas sembradas", 
       yaxis_title = 'Cantidad de hectáreas')

fig.show()

fig = px.box(df_hma[(df_hma['Hectareas']>0) & (df_hma['Segmento']=='Sembradas')], 
             x= "Campaña", y="Hectareas", points="all")
#fig.update_traces(quartilemethod="exclusive")
fig.update_layout(title = "Boxplot de observaciones de hectáreas sembradas por campaña", 
       xaxis_title = 'Campaña', yaxis_title = 'Cantidad de hectáreas')

fig.show()

"""### Sembradas / Total trabajadas"""

sembradas = df_hma[['Campaña','Hectareas','Segmento']]
sembradas = sembradas.groupby(['Campaña','Segmento']).sum()
sembradas.reset_index(inplace=True, drop=False)
sembradas = sembradas[sembradas['Segmento']=="Sembradas"]
sembradas['Segmento'] = 'Sembradas'

trabajadas = df_hma[['Campaña','Hectareas']]
trabajadas = trabajadas.groupby(['Campaña']).sum()
trabajadas.reset_index(inplace=True, drop=False)
trabajadas['Segmento'] = 'Total trabajadas'

tabla = pd.concat([sembradas,trabajadas])
tabla["Hectareas"] = tabla["Total"].astype(int)

fig = px.histogram(tabla, x="Campaña", y="Hectareas",
             color='Segmento', barmode='group',text_auto='.4s',
             height=400)
fig.update_layout(title = "Hectareas sembrada y trabajadas", 
      xaxis_title = 'Campaña', yaxis_title = 'Cantidad de hectáreas')
fig.show()

fig = px.box(df_hma[df_hma['Hectareas']>0],x="Cereal", y="Hectareas", color="Campaña")

fig.update_traces(quartilemethod="exclusive")

fig.show()

fig = px.box(df_hma[df_hma['Hectareas']>0],x="Campaña", y="Hectareas", color="Cereal")

fig.update_traces(quartilemethod="exclusive")

fig.show()

df_hma['Cereal'].unique()



fig = px.box(df_hma[df_hma['Hectareas']>0],x="Campaña", y="Hectareas", color="Etapa")

fig.update_traces(quartilemethod="exclusive")

fig.show()

"""### Por productor"""

#Análisis por productor

trabajadas_etapa = df_hma.groupby(['Cuenta','Etapa','Campaña']).sum()
trabajadas_etapa.reset_index(inplace = True, drop=False)
trabajadas_etapa = trabajadas_etapa[trabajadas_etapa['Hectareas']>0]
trabajadas_etapa.head(10)

fig = px.box(trabajadas_etapa[trabajadas_etapa['Hectareas']>0],x="Etapa", y="Hectareas", color="Campaña")

fig.update_traces(quartilemethod="exclusive")

fig.show()

#Análisis de distribución e inferencial por productor

trabajadas = df_hma.groupby(['Cuenta']).sum()
trabajadas.reset_index(inplace = True, drop=False)
trabajadas = trabajadas[trabajadas['Hectareas']>0]

trabajadas['trabajadas_promedio_ultimas_3'] = trabajadas['Hectareas'] / 3

asimetria = str(scipy.stats.skew(trabajadas['trabajadas_promedio_ultimas_3']))
kurtosis = str(scipy.stats.kurtosis(trabajadas['trabajadas_promedio_ultimas_3']))
print( 'Asimetria de: ' + asimetria)
print( 'Kurtosis de: ' + kurtosis )

stat, p = shapiro(trabajadas['trabajadas_promedio_ultimas_3'])
print('Estadisticos=%.3f, p=%.3f' % (stat, p))

# Interpretación
alpha = 0.05
if p > alpha:
    print('La variable parece Gaussiana o Normal (no se rechaza la hipótesis nula H0)')
else:

    print('La variable no parece Gaussiana o Normal(se rechaza la hipótesis nula H0)')
    print(' ')

fig = px.histogram(trabajadas, x='trabajadas_promedio_ultimas_3', nbins=100)
fig.show()

#Análisis Hectareas (h) suma

df_ht = df_hma[df_hma['Hectareas']>0] #solo datos de "h" trabajadas

#df_ht = round(df_ht.groupby(['Cereal','Campaña']).sum(), 0)
df_ht = pd.DataFrame(round(df_ht.groupby(['Cereal','Campaña']).sum(), 0))
df_ht.reset_index(drop=False, inplace=True)

df_ht = pd.pivot_table(df_ht, values='Hectareas', index=['Campaña'],
                    columns=['Cereal'])#, aggfunc=np.sum)
df_ht.reset_index(drop=False, inplace=True)

# decimals = pd.Series([0, 0, 0, 0, 0], index=['Maíz 1º', 'Maíz 2º', 'Soja 1º', 'Soja 2º', 'Trigo'])
# df_ht = df_ht.round(decimals)

cm = sbn.light_palette("green", as_cmap=True)
df_ht.style.background_gradient(cmap=cm)

#Análisis Hectareas (h) conteo

df_ht = df_hma[df_hma['Hectareas']>0] #solo datos de "h" trabajadas

#df_ht = round(df_ht.groupby(['Cereal','Campaña']).sum(), 0)
df_ht = pd.DataFrame(round(df_ht.groupby(['Cereal','Campaña']).count(), 0))
df_ht.reset_index(drop=False, inplace=True)

df_ht = pd.pivot_table(df_ht, values='Hectareas', index=['Campaña'],
                    columns=['Cereal'])#, aggfunc=np.sum)
df_ht.reset_index(drop=False, inplace=True)

# decimals = pd.Series([0, 0, 0, 0, 0], index=['Maíz 1º', 'Maíz 2º', 'Soja 1º', 'Soja 2º', 'Trigo'])
# df_ht = df_ht.round(decimals)

cm = sbn.light_palette("green", as_cmap=True)
df_ht.style.background_gradient(cmap=cm)

#Análisis Hectareas (h) promedio

df_ht = df_hma[df_hma['Hectareas']>0] #solo datos de "h" trabajadas

#df_ht = round(df_ht.groupby(['Cereal','Campaña']).mean(), 0)
df_ht = pd.DataFrame(round(df_ht.groupby(['Cereal','Campaña']).mean(), 0))
df_ht.reset_index(drop=False, inplace=True)

df_ht = pd.pivot_table(df_ht, values='Hectareas', index=['Campaña'],
                    columns=['Cereal'], aggfunc=np.sum)
df_ht.reset_index(drop=False, inplace=True)

cm = sbn.light_palette("green", as_cmap=True)
df_ht.style.background_gradient(cmap=cm)

"""<ins>text</ins>"""

